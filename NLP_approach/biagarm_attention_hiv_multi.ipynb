{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import tempfile\n",
    "from collections import Counter\n",
    "from typing import List, Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MolFromSmiles, MolToSmiles, CanonSmiles\n",
    "\n",
    "import deepchem as dc\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "\n",
    "import atomInSmiles as ais\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the integer based vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This vocab only focus in characters not in pairs.\n",
    "class CreateVocab:\n",
    "    def __init__(self, datasets):\n",
    "        \"\"\"\n",
    "        Initialize the CreateVocab object with multiple datasets.\n",
    "\n",
    "        :param datasets: List of datasets (strings) to build the vocabulary from.\n",
    "        \"\"\"\n",
    "        self.stoi = {}\n",
    "        self.itos = {}\n",
    "        self.build_vocab(datasets)\n",
    "\n",
    "    def build_vocab(self, datasets):\n",
    "        \"\"\"\n",
    "        Builds the vocabulary from the given datasets.\n",
    "\n",
    "        :param datasets: List of datasets (strings) to build the vocabulary from.\n",
    "        \"\"\"\n",
    "        all_text = ''.join(datasets)  # Concatenate all datasets\n",
    "        unique_chars = sorted(set(all_text))  # Extract unique characters\n",
    "\n",
    "        self.stoi = {char: idx for idx, char in enumerate(unique_chars)}\n",
    "        self.itos = {idx: char for idx, char in enumerate(unique_chars)}\n",
    "\n",
    "    def encode(self, text):\n",
    "        \"\"\"\n",
    "        Encodes a given text into a list of indices.\n",
    "\n",
    "        :param text: String to be encoded.\n",
    "        :return: List of indices corresponding to the characters in the text.\n",
    "        \"\"\"\n",
    "        return [self.stoi[char] for char in text]\n",
    "\n",
    "    def decode(self, indices):\n",
    "        \"\"\"\n",
    "        Decodes a list of indices into a string.\n",
    "\n",
    "        :param indices: List of indices to be decoded.\n",
    "        :return: Decoded string.\n",
    "        \"\"\"\n",
    "        return ''.join(self.itos[idx] for idx in indices)\n",
    "\n",
    "\n",
    "# Processing the datasets\n",
    "def preprocess_smiles(smiles_data):\n",
    "    processed_text = \"\"\n",
    "    for smile in smiles_data:\n",
    "        sections = separate(smile)\n",
    "        all_sections = show_sections(smile, sections)\n",
    "        processed_text += \" \".join(all_sections) + \"*\"\n",
    "    return processed_text\n",
    "\n",
    "# Load and process datasets\n",
    "smile_1 = pd.read_csv('smile_1.csv')['smiles']\n",
    "smile_2 = pd.read_csv('smile_2.csv')['smiles']\n",
    "smile_3 = pd.read_csv('smile_3.csv')['canonical_smiles']\n",
    "\n",
    "#processed_smile_1 = preprocess_smiles(smile_1)\n",
    "#processed_smile_2 = preprocess_smiles(smile_2)\n",
    "#processed_smile_3 = preprocess_smiles(smile_3)\n",
    "\n",
    "# Combine processed datasets\n",
    "combined_text = str(smile_1) + str(smile_2) + str(smile_3) + \"*\"\n",
    "\n",
    "# Create vocabulary\n",
    "vocab = CreateVocab([combined_text])\n",
    "\n",
    "# Now vocab.stoi and vocab.itos are your dictionaries\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding the data for the model (i.e., which data set areyou using?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m encoded_text \u001b[38;5;241m=\u001b[39m \u001b[43mvocab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Train and test splits\u001b[39;00m\n\u001b[0;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(encoded_text, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n",
      "Cell \u001b[1;32mIn[62], line 32\u001b[0m, in \u001b[0;36mCreateVocab.encode\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m    Encodes a given text into a list of indices.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m    :param text: String to be encoded.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    :return: List of indices corresponding to the characters in the text.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstoi\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchar\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[1;32mIn[62], line 32\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m    Encodes a given text into a list of indices.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m    :param text: String to be encoded.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    :return: List of indices corresponding to the characters in the text.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstoi\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchar\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m text]\n",
      "\u001b[1;31mKeyError\u001b[0m: \"'\""
     ]
    }
   ],
   "source": [
    "encoded_text = vocab.encode(text)\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encoded_text, dtype=torch.long)\n",
    "n = int(0.9 * len(data))  # 90% for training, rest for validation\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 78 # what is the maximum context length for predictions?\n",
    "max_iters = 350\n",
    "eval_interval = 10\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 100\n",
    "n_embd = 64\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ------------\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "vocab_size = len(vocab.stoi)\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "# super simple bigram model\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\n', 1: ' ', 2: '#', 3: '(', 4: ')', 5: '*', 6: '+', 7: ',', 8: '-', 9: '.', 10: '0', 11: '1', 12: '2', 13: '3', 14: '4', 15: '5', 16: '6', 17: '7', 18: '8', 19: '9', 20: ':', 21: '=', 22: '@', 23: 'B', 24: 'C', 25: 'F', 26: 'H', 27: 'L', 28: 'N', 29: 'O', 30: 'P', 31: 'S', 32: '[', 33: '\\\\', 34: ']', 35: '_', 36: 'a', 37: 'b', 38: 'c', 39: 'd', 40: 'e', 41: 'g', 42: 'h', 43: 'i', 44: 'j', 45: 'l', 46: 'm', 47: 'n', 48: 'o', 49: 'p', 50: 'r', 51: 's', 52: 't', 53: 'u', 54: 'y'}\n"
     ]
    }
   ],
   "source": [
    "print(vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary (Character to Index):\n",
      "'\n",
      "': 0\n",
      "' ': 1\n",
      "'#': 2\n",
      "'(': 3\n",
      "')': 4\n",
      "'*': 5\n",
      "'+': 6\n",
      "',': 7\n",
      "'-': 8\n",
      "'.': 9\n",
      "'0': 10\n",
      "'1': 11\n",
      "'2': 12\n",
      "'3': 13\n",
      "'4': 14\n",
      "'5': 15\n",
      "'6': 16\n",
      "'7': 17\n",
      "'8': 18\n",
      "'9': 19\n",
      "':': 20\n",
      "'=': 21\n",
      "'@': 22\n",
      "'B': 23\n",
      "'C': 24\n",
      "'F': 25\n",
      "'H': 26\n",
      "'L': 27\n",
      "'N': 28\n",
      "'O': 29\n",
      "'P': 30\n",
      "'S': 31\n",
      "'[': 32\n",
      "'\\': 33\n",
      "']': 34\n",
      "'_': 35\n",
      "'a': 36\n",
      "'b': 37\n",
      "'c': 38\n",
      "'d': 39\n",
      "'e': 40\n",
      "'g': 41\n",
      "'h': 42\n",
      "'i': 43\n",
      "'j': 44\n",
      "'l': 45\n",
      "'m': 46\n",
      "'n': 47\n",
      "'o': 48\n",
      "'p': 49\n",
      "'r': 50\n",
      "'s': 51\n",
      "'t': 52\n",
      "'u': 53\n",
      "'y': 54\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary (Character to Index):\")\n",
    "for char, idx in vocab.stoi.items():\n",
    "    print(f\"'{char}': {idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the model, Do not call!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.209342 M parameters\n"
     ]
    }
   ],
   "source": [
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.4394, val loss 4.4283\n",
      "step 10: train loss 2.7632, val loss 2.7667\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iters):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Evaluate the loss periodically\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m%\u001b[39m eval_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m==\u001b[39m max_iters \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m----> 4\u001b[0m         losses \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28miter\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: train loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Get a batch of data\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rebe\\Documents\\Python programms\\Capstone_code\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 35\u001b[0m, in \u001b[0;36mestimate_loss\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(eval_iters):\n\u001b[0;32m     34\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m get_batch(split)\n\u001b[1;32m---> 35\u001b[0m     logits, loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     losses[k] \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     37\u001b[0m out[split] \u001b[38;5;241m=\u001b[39m losses\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32mc:\\Users\\Rebe\\Documents\\Python programms\\Capstone_code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rebe\\Documents\\Python programms\\Capstone_code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 132\u001b[0m, in \u001b[0;36mBigramLanguageModel.forward\u001b[1;34m(self, idx, targets)\u001b[0m\n\u001b[0;32m    130\u001b[0m pos_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_table(torch\u001b[38;5;241m.\u001b[39marange(T, device\u001b[38;5;241m=\u001b[39mdevice)) \u001b[38;5;66;03m# (T,C)\u001b[39;00m\n\u001b[0;32m    131\u001b[0m x \u001b[38;5;241m=\u001b[39m tok_emb \u001b[38;5;241m+\u001b[39m pos_emb \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[0;32m    133\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_f(x) \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[0;32m    134\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(x) \u001b[38;5;66;03m# (B,T,vocab_size)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rebe\\Documents\\Python programms\\Capstone_code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rebe\\Documents\\Python programms\\Capstone_code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rebe\\Documents\\Python programms\\Capstone_code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Rebe\\Documents\\Python programms\\Capstone_code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rebe\\Documents\\Python programms\\Capstone_code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 109\u001b[0m, in \u001b[0;36mBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 109\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msa\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffwd(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln2(x))\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Rebe\\Documents\\Python programms\\Capstone_code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rebe\\Documents\\Python programms\\Capstone_code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 77\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 77\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\u001b[43m[\u001b[49m\u001b[43mh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheads\u001b[49m\u001b[43m]\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     78\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(out))\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "Cell \u001b[1;32mIn[11], line 77\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 77\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[43mh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     78\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(out))\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Rebe\\Documents\\Python programms\\Capstone_code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rebe\\Documents\\Python programms\\Capstone_code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    # Evaluate the loss periodically\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # Get a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # Forward pass and loss computation\n",
    "    logits, loss = model(xb, yb)\n",
    "\n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'CC(C)CN(Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc12)NC(=O)N1CCOCC1*', 'CC(C)CN(Sc1ccc2c(c1)OCCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc12)NC(=O)N1CCOCC1*', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)NC(=O)N1CCOCC1)S(=O)(=O)c1ccc2c(c1)CCO2*', 'Cc1c(O)cccc1C(=O)N[C@@H](Cc1ccccc1Br)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1*', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)NC(=O)c1cccc(=O)[nH]1)S(=O)(=O)c1ccc(N)cc1*', 'Cc1ccccc1C[C@H](NC(=O)c1cccnc1)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1*', 'O=C(O)CNC(=O)c1c(=O)oc(O)c2cc(Br)ccc12*', 'C[C@H](NC(=O)c1c(=O)oc(O)c2cccc(-c3cccc(C(F)(F)F)c3)c12)C(=O)O*', 'Cc1ccccc1C[C@H](NC(=O)c1cccc(C)c1O)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1*', 'COC(=O)N[C@@H](CC1CCCCC1)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1*', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](CC1CCCCC1)NC(=O)c1cccnc1)S(=O)(=O)c1ccc(N)cc1*', 'Cc1ccc(C(=O)N[C@@H](CC2CCCCC2)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c2ccc(N)cc2)cn1*', 'COC(=O)N[C@H](C(=O)NCCCC[C@H](CO)N(CC(C)C)S(=O)(=O)c1cccc2cccnc12)C(c1ccccc1)c1ccccc1*', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Cl)NC(=O)c1ccncc1)S(=O)(=O)c1ccc(N)cc1*', 'Cc1ncccc1C(=O)N[C@@H](Cc1ccccc1Cl)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1*', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](CC1=C(Br)CCC=C1)NC(=O)N1CCOCC1)S(=O)(=O)c1ccc2c(c1)OCCO2*', 'COC(=O)N[C@H](C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c1ccc2c(c1)CCO2)C(C1=CC=CCC1)c1ccccc1*', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](NC(=O)N1CCOCC1)C(c1ccccc1)c1ccccc1)S(=O)(=O)c1ccc2c(c1)CCO2*', 'COC(=O)N[C@H](C(=O)NCCCC[C@H](CO)N(CC(C)C)S(=O)(=O)c1ccc2c(c1)N(C)CCO2)C(c1ccccc1)c1ccccc1*', 'Cc1cccnc1C(=O)N[C@@H](Cc1ccccc1Br)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1*', 'Cc1ccc(C(=O)N[C@@H](Cc2ccccc2Br)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c2ccc(N)cc2)cc1O*', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)NC(=O)OCc1ccncc1)S(=O)(=O)c1ccc(N)cc1*', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccc2ccccc2c1)NS(=O)(=O)c1ccc2c(c1)OCCC2C)S(=O)(=O)c1ccc(N)cc1*', 'CCC(=O)NC(=O)N(C)CC(=O)N[C@@H](Cc1ccc2ccccc2c1)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1*', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccc2ccccc2c1)NCc1ccccn1)S(=O)(=O)c1ccc(N)cc1*', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](NS(=O)(=O)c1cccs1)C(c1ccccc1)c1ccccc1)S(=O)(=O)c1ccc(N)cc1*', 'CN[C@H](C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1)C(c1ccccc1)C1C=CC=CC1*', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](NC(=O)NCC1=CCCN=C1)C(c1ccccc1)c1ccccc1)S(=O)(=O)c1ccc(N)cc1*', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](NC(=O)NCc1ccncc1)C(c1ccccc1)c1ccccc1)S(=O)(=O)c1ccc(N)cc1*', 'Cc1ccc(C(=O)N[C@@H](Cc2ccccc2C)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c2ccc(N)cc2)cc1O*', 'COC(=O)N[C@H](C(=O)NCCCCC(C(N)=O)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1)C(c1ccccc1)c1ccccc1*', 'COC(=O)N[C@H](C(=O)NCCCC[C@@H](CO)N(Cc1cccnc1)S(=O)(=O)c1ccc(N)cc1)C(c1ccccc1)c1ccccc1*', 'Cc1ncccc1C(=O)N[C@@H](Cc1ccccc1Br)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1*', 'Cc1ccc(C(=O)N[C@@H](Cc2ccccc2Br)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c2ccc(N)cc2)cn1*', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](Cc1ccccc1Br)NC(=O)c1ccc2c(c1)OCO2)S(=O)(=O)c1ccc(N)cc1*', 'CC(C)CN([C@H](CO)CCCCNC(=O)C(Cc1ccccc1Br)NC(=O)c1ccncc1)S(=O)(=O)c1ccc(N)cc1*', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)NC(=O)C1=NCC(C)N=C1)S(=O)(=O)c1ccc(N)cc1*', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)NC(=O)c1cnccn1)S(=O)(=O)c1ccc(N)cc1*', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](Cc1ccccc1Br)NC(=O)c1ccccn1)S(=O)(=O)c1ccc(N)cc1*', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](Cc1ccccc1Br)NC(=O)c1cccnc1)S(=O)(=O)c1ccc(N)cc1*', 'COC(=O)N[C@H](C(=O)NCCCC[C@H](C(N)=O)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1)C(c1ccccc1)c1ccccc1*', 'CC(=O)N[C@H](C(=O)NCCCCC(C(N)=O)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1)C(c1ccccc1)c1ccccc1*', 'CC(C)CN(C(CCCCNC(=O)[C@H](CC1=C2C=CC=CC2CC=C1)NC(=O)N1CCOCC1)C(N)=O)S(=O)(=O)c1ccc(N)cc1*', 'COc1cc2cc(C#N)ccc2c(OC)c1Oc1cc(N)nc(Nc2ccc(C#N)cc2)n1*', 'CCNc1cc(Oc2c(OC)cc3cc(C#N)ccc3c2OC)nc(Nc2ccc(C#N)cc2)n1*', 'COc1cc2cc(C#N)ccc2c(OC)c1Oc1cc(N2CCC(O)C2)nc(Nc2ccc(C#N)cc2)n1*', 'Cc1ccnc2c1NC(=O)c1cccnc1N2C1CC1*', 'Cc1cc(C#N)cc(C)c1Oc1nc(Nc2ccc(C#N)cc2)nc(N)c1Br*', 'O=C1Nc2ccc(Cl)cc2[C@@](C#CC2CC2)(C(F)(F)F)O1*', 'C=CC(=O)N(C)c1cc(Oc2ccccc2OCCn2ccc(=O)[nH]c2=O)c(C)c2cc(C#N)ccc12*', 'Cc1c(Oc2ccccc2OCCn2ccc(=O)[nH]c2=O)cc(N(C)C(=O)CCl)c2ccc(C#N)cc12*', 'CC(C)c1ccc(O)c(=O)c(O)c1*'\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "smiles_1 = pd.read_csv('smile_3.csv')\n",
    "#smiles_1\n",
    "smiles_1 = smiles_1['canonical_smiles']\n",
    "#smiles_1\n",
    "\n",
    "\n",
    "text = [str(i) + \"*\" for i in smiles_1]\n",
    "\n",
    "text = str(text)[1:-1]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CC (C) CN (Sc1ccc2c(c1)CCO2) [C@H] (CO) CCCCNC (=O) [C@@H] (Cc1cccc2ccccc12) NC (=O) N1CCOCC1'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def separate(s):\n",
    "    stack = []\n",
    "    sections = []\n",
    "    for i, c in enumerate(s):\n",
    "        if c in ['(', '[']:\n",
    "            stack.append((c, i))\n",
    "        elif c in [')', ']']:\n",
    "            while stack:\n",
    "                opening, start = stack[-1]  # Peek at the top of the stack\n",
    "                if (opening == '(' and c == ')') or (opening == '[' and c == ']'):\n",
    "                    stack.pop()  # Remove the matching opening bracket\n",
    "                    sections.append((start, i))\n",
    "                    break\n",
    "                else:\n",
    "                    stack.pop()  # Remove the non-matching opening bracket\n",
    "\n",
    "    # Filter out overlapping sections\n",
    "    non_overlapping_sections = []\n",
    "    last_end = -1\n",
    "    for start, end in sorted(sections, key=lambda x: x[0]):\n",
    "        if start > last_end:\n",
    "            non_overlapping_sections.append((start, end))\n",
    "            last_end = end\n",
    "\n",
    "    return non_overlapping_sections\n",
    "\n",
    "\n",
    "def show_sections(s, sections):\n",
    "    all_sections = []\n",
    "    last_end = 0  # To keep track of the last section's end index\n",
    "\n",
    "    for start, end in sections:\n",
    "        if start > last_end:\n",
    "            # Add the section between the last end and this start\n",
    "            all_sections.append(s[last_end:start])\n",
    "        # Add the section within the current parenthesis/bracket\n",
    "        all_sections.append(s[start:end+1])\n",
    "        last_end = end + 1  # Update the last end index\n",
    "\n",
    "    # Handle any remaining section after the last parenthesis/bracket\n",
    "    if last_end < len(s):\n",
    "        all_sections.append(s[last_end:])\n",
    "\n",
    "    return all_sections\n",
    "\n",
    "smiles = smiles_1 \n",
    "s = smiles[0]\n",
    "sections = separate(s)\n",
    "all_sections = show_sections(s, sections)\n",
    "\" \".join(all_sections)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:00<00:00, 12239.96it/s]\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\n",
    "\n",
    "for i in tqdm(range(len(smiles))):\n",
    "    sections = separate(smiles[i])\n",
    "    all_sections = show_sections(s, sections)\n",
    "    text += \" \".join(all_sections)\n",
    "    text += \"* \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC (C) CN (Sc1ccc2c(c1)CCO2) [C@H] (CO) CCCCNC (=O) [C@@H] (Cc1cccc2ccccc12) NC (=O) N1CCOCC1*CC (C) CN (Sc1ccc2c(c1)CCO2)[ C@H]( CO)C CCCNC( =O)[ C@@H]( Cc1cccc2ccccc12)N C( =O)N 1CCOCC1*CC (C) CN (Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2c c ccc1 2)NC (=O)N1C COCC 1*CC(C )CN (Sc1cc c2c( c 1)CCO2 )[C@H](CO)CCC C NC(= O)[C@ @H](Cc 1ccc c 2ccccc12 ) NC(= O)N1 CCOCC 1*CC (C) CN (Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc12) N C(=O )N1C COCC1 *CC(C)CN(Sc 1ccc2 c(c1)CCO2)[C@H]( C O)CC CCNC( =O)[C@ @H]( C c1cccc2c c ccc1 2)NC (=O)N 1CC OCC1*CC( C)C N(S c1cc c2c (c1) CC O2) [C@H ](CO )CCCCNC(=O)[C@@H](Cc1cccc2ccccc12)NC(=O)N1CCOCC1*C C(C)C N(Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cc c c2cc ccc12)NC(=O)N1CCOCC1*CC(C)CN(Sc 1ccc2 c(c1)CCO2)[C@H](CO)C C CCNC (=O)[ C@@H]( Cc1c c cc2ccccc 1 2)NC (=O) N1CCO CC1*CC( C)CN ( Sc1ccc 2c(c1)CCO2) [ C@H] (CO)C CCCNC( =O)[ C @@H](Cc1 c ccc2 cccc c12)N C(= O)N1CCOCC1*CC (C) CN (Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc 2 cccc c12) NC(=O )N1 CCOCC1*CC(C)C N(Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc12)NC(=O)N1CCOCC 1*CC( C)CN ( Sc1cc c2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc12 ) NC(=O)N1CC OCC1*CC (C) CN (Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2c c ccc1 2)NC (=O)N 1CC OCC1*CC(C)CN(Sc 1ccc 2 c(c1)C CO2)[C@H](CO) C CCCN C(=O) [C@@H] (Cc1 c ccc2cccc c 12)N C(=O )N1CC OCC 1*CC (C) CN (Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc 1 2)NC (=O) N1CCOCC 1*CC( C)CN ( Sc1cc c2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc12)N C (=O)N1CCOCC1*CC (C) CN (Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc12)NC ( =O)N 1CCO CC1 *CC( C)CN ( Sc1cc c2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc12)NC(= O )N1CCOCC1*CC(C)CN(Sc 1ccc 2 c(c1)C CO2)[C@H](CO) C CCCN C(=O) [C@@H] (Cc1 c ccc2cccc c 12)N C(=O )N1CC OCC 1*CC(C)C N(Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc12)NC(=O)N1CCOCC1*CC (C) CN (Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccc c c12) NC(= O)N1C COC C1*CC (C) CN (Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc12)NC(=O)N1CC O CC1   *CC( C)CN (S c1cc c 2c( c1 )CCO 2 )[C@H] (CO)CCCCNC(=O)[C@ @ H](C c1ccc c2cccc c12) N C(=O)N1C C OCC1   *CC (C) CN (Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2c c ccc1 2)NC (=O)N 1CC OCC1*CC (C) CN (Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc12)NC(=O ) N1CC OCC1  *CC (C)CN (Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc 2 ccccc12)NC (=O)N1CCOCC1*CC (C) CN (Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc12)NC(=O) N 1CCO CC1  *CC (C) CN (Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc12)NC(= O )N1C COCC 1 *CC(C)C N(Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc12)NC(=O)N1CCOCC1*CC( C)CN ( Sc1cc c2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2cccc c 12)NC(=O)N 1CCOCC1*CC( C)CN ( Sc1cc c2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc12) N C(=O)N1CCO CC1*CC(C)CN(Sc 1ccc 2 c(c1)C CO2)[C@H](CO) C CCCN C(=O) [C@@H] (Cc1 c ccc2cccc c 12)N C(=O )N1CC OCC 1*CC(C)C N(Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc12)NC(=O)N1CCOCC1*CC (C) CN (Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc12)N C (=O) N1CC OCC1 *CC (C) CN (Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cc c c2cc ccc1 2)NC( =O) N1CCOCC1*CC (C) CN (Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc1 2 )NC( =O)N 1CCOC C1*CC (C) CN (Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2c c ccc1 2)NC (=O)N 1CC OCC1*CC (C) CN (Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2cc c cc12 )NC( =O)N1 CCO CC1*CC (C) CN (Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2cc c cc12 )NC( =O)N1 CCO CC1*CC( C)CN ( Sc1cc c2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc12) N C(=O)N1CCO CC1*CC (C)C N (Sc1c cc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccc c c12)NC(=O) N1CCOCC1*CC (C) CN (Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc12)N C (=O) N1CC OCC1 *CC(C)CN(S c1ccc 2c(c1 )CCO 2)[C@H] (CO )C CCCNC(=O)[C@@H]( Cc1cccc2ccccc12)NC(=O)N1CCOCC1*CC(C)CN (Sc1ccc2c(c1)CCO2)[C@H](CO)C CC CNC(=O)[C@@H](Cc 1cccc2ccccc12)NC(=O)N1CCOCC1*CC(C)CN(S c1ccc 2c(c1 )CCO 2)[C@H] (CO)CCCCNC(= O) [C@@H](Cc1cccc2c cccc12)NC(=O)N1CCOCC1*CC(C)CN(Sc1c cc2c (c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc12)NC(=O)N1CCOCC1*CC(C) CN(Sc 1c cc2 c(c1)CC O2)[C@H](CO)CCCC NC (=O )[C@@H](Cc1cccc2ccccc12)NC(=O)N1CCOCC1*CC(C)CN(Sc 1ccc 2c( c1)CC O2)[C@H](C O)CCCCNC(= O)[C@@H](Cc1cccc2ccccc12)NC(=O)N1CCOCC1*CC(C )CN( S c1c cc2c (c1)CCO2)[C@H](CO)CCCCNC(=O)[C@ @ H]( Cc1c ccc2c cccc12)NC(=O)N1CCOCC1*CC(C )CN(Sc1ccc2c(c1)CCO2)[C@H](CO)C CC CNC(=O)[C@@H]( Cc1cc cc2cc ccc12)NC(=O)N1CCOCC1*CC (C) CN(Sc 1cc c 2c(c 1 )CC O2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc12)NC(=O)N1CCOCC1*\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m.generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = vocab.decode(m.generate(context, max_new_tokens=200)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc1c2)NC(R1CCO) CC1*CC @H](Cc1c c cc2c cccc12)NC(=O)N@H]( 1C CO) C CCNC(=O)[C@@H]( Cc1cccc2ccc cc12 )NC(=O)N1CCOCC 1*CC(C)CN (Sc1ccc2c(c1)CCO2)[C@H](CO)CCC NC\n"
     ]
    }
   ],
   "source": [
    "print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the generated data for vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nCCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc1c2)NC(R1CCO)CC1',\n",
       " 'CC@H](Cc1cccc2ccccc12)NC(=O)N@H](1CCO)CCCNC(=O)[C@@H](Cc1cccc2ccccc12)NC(=O)N1CCOCC1',\n",
       " 'CC(C)CN(Sc1ccc2c(c1)CCO2)[C@H](CO)CCCNC']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = \"\".join(val)\n",
    "new = new.split('*')\n",
    "\n",
    "new = [s for s in new if len(s) > 2]\n",
    "\n",
    "new = [s.replace(' ', '') for s in new]\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[14:33:50] SMILES Parse Error: extra close parentheses while parsing: CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc1c2)NC(R1CCO)CC1\n",
      "[14:33:50] SMILES Parse Error: Failed parsing SMILES '\n",
      "CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc1c2)NC(R1CCO)CC1' for input: '\n",
      "CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc1c2)NC(R1CCO)CC1'\n",
      "[14:33:50] SMILES Parse Error: syntax error while parsing: CC@H](Cc1cccc2ccccc12)NC(=O)N@H](1CCO)CCCNC(=O)[C@@H](Cc1cccc2ccccc12)NC(=O)N1CCOCC1\n",
      "[14:33:50] SMILES Parse Error: Failed parsing SMILES 'CC@H](Cc1cccc2ccccc12)NC(=O)N@H](1CCO)CCCNC(=O)[C@@H](Cc1cccc2ccccc12)NC(=O)N1CCOCC1' for input: 'CC@H](Cc1cccc2ccccc12)NC(=O)N@H](1CCO)CCCNC(=O)[C@@H](Cc1cccc2ccccc12)NC(=O)N1CCOCC1'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "\n",
    "mols = [Chem.MolFromSmiles(smi) for smi in new if Chem.MolFromSmiles(smi) is not None]\n",
    "Draw.MolsToGridImage(mols, molsPerRow=5, subImgSize=(200, 200), legends=[str(i) for i in range(len(mols))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_path = \"1_1_big_data_biagarm_char.pkl\"\n",
    "torch.save(model.state_dict(), model_state_path)\n",
    "\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('smile_2.csv')\n",
    "\n",
    "smiles = data['smiles']\n",
    "#smiles = data['canonical_smiles']\n",
    "#print(len(smiles))\n",
    "\n",
    "text = str(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C (=Cc1ccccc1) C1= [O+] [Cu-3] 2 ([O+]=C(C=Cc3ccccc3)CC(c3ccccc3)=[O+]2) [O+] =C (c2ccccc2) C1'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = smiles[0]\n",
    "sections = separate(s)\n",
    "all_sections = show_sections(s, sections)\n",
    "\" \".join(all_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32900 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32900/32900 [00:43<00:00, 764.12it/s] \n"
     ]
    }
   ],
   "source": [
    "text = \"\"\n",
    "\n",
    "for i in tqdm(range(len(smiles))):\n",
    "    sections = separate(smiles[i])\n",
    "    all_sections = show_sections(s, sections)\n",
    "    text += \" \".join(all_sections)\n",
    "    text += \"*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method BigramLanguageModel.generate of BigramLanguageModel(\n",
      "  (token_embedding_table): Embedding(46, 64)\n",
      "  (position_embedding_table): Embedding(32, 64)\n",
      "  (blocks): Sequential(\n",
      "    (0): Block(\n",
      "      (sa): MultiHeadAttention(\n",
      "        (heads): ModuleList(\n",
      "          (0-3): 4 x Head(\n",
      "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
      "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
      "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffwd): FeedFoward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (3): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (1): Block(\n",
      "      (sa): MultiHeadAttention(\n",
      "        (heads): ModuleList(\n",
      "          (0-3): 4 x Head(\n",
      "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
      "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
      "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffwd): FeedFoward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (3): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (2): Block(\n",
      "      (sa): MultiHeadAttention(\n",
      "        (heads): ModuleList(\n",
      "          (0-3): 4 x Head(\n",
      "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
      "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
      "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffwd): FeedFoward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (3): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (3): Block(\n",
      "      (sa): MultiHeadAttention(\n",
      "        (heads): ModuleList(\n",
      "          (0-3): 4 x Head(\n",
      "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
      "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
      "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ffwd): FeedFoward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (3): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (ln_f): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (lm_head): Linear(in_features=64, out_features=46, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(m.generate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second fine tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('smile_3.csv')\n",
    "smiles = data['canonical_smiles']\n",
    "\n",
    "np.min([len(s) for s in smiles])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
