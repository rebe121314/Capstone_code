{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nstoi = {ch: i for i, ch in enumerate(chars)}\\nitos = {i: ch for i, ch in enumerate(chars)}\\nencode = lambda s: [stoi[c] for c in s]\\ndecode = lambda l: ''.join([itos[i] for i in l])\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv('hiv_protease_inhibitors_data_chemlb_full.csv')\n",
    "\n",
    "smiles = list(data['canonical_smiles'])\n",
    "#smiles\n",
    "\n",
    "text = \" \".join(smiles)\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC(C)CN(Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc12)NC(=O)N1CCOCC1\n"
     ]
    }
   ],
   "source": [
    "print(smiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CC (C) CN (Sc1ccc2c(c1)CCO2) [C@H] (CO) CCCCNC (=O) [C@@H] (Cc1cccc2ccccc12) NC (=O) N1CCOCC1'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#separete a string  into sections with valid parenthesis or brackets\n",
    "\n",
    "def separate(s):\n",
    "    stack = []\n",
    "    sections = []\n",
    "    for i, c in enumerate(s):\n",
    "        if c in ['(', '[']:\n",
    "            stack.append((c, i))\n",
    "        elif c in [')', ']']:\n",
    "            while stack:\n",
    "                opening, start = stack[-1]  # Peek at the top of the stack\n",
    "                if (opening == '(' and c == ')') or (opening == '[' and c == ']'):\n",
    "                    stack.pop()  # Remove the matching opening bracket\n",
    "                    sections.append((start, i))\n",
    "                    break\n",
    "                else:\n",
    "                    stack.pop()  # Remove the non-matching opening bracket\n",
    "\n",
    "    # Filter out overlapping sections\n",
    "    non_overlapping_sections = []\n",
    "    last_end = -1\n",
    "    for start, end in sorted(sections, key=lambda x: x[0]):\n",
    "        if start > last_end:\n",
    "            non_overlapping_sections.append((start, end))\n",
    "            last_end = end\n",
    "\n",
    "    return non_overlapping_sections\n",
    "\n",
    "\n",
    "def show_sections(s, sections):\n",
    "    all_sections = []\n",
    "    last_end = 0  # To keep track of the last section's end index\n",
    "\n",
    "    for start, end in sections:\n",
    "        if start > last_end:\n",
    "            # Add the section between the last end and this start\n",
    "            all_sections.append(s[last_end:start])\n",
    "        # Add the section within the current parenthesis/bracket\n",
    "        all_sections.append(s[start:end+1])\n",
    "        last_end = end + 1  # Update the last end index\n",
    "\n",
    "    # Handle any remaining section after the last parenthesis/bracket\n",
    "    if last_end < len(s):\n",
    "        all_sections.append(s[last_end:])\n",
    "\n",
    "    return all_sections\n",
    "\n",
    "s = smiles[0]\n",
    "sections = separate(s)\n",
    "all_sections = show_sections(s, sections)\n",
    "\" \".join(all_sections)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "\n",
    "for s in smiles:\n",
    "    sections = separate(s)\n",
    "    all_sections = show_sections(s, sections)\n",
    "    text += \" \".join(all_sections)\n",
    "    text += \"*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CC (C) CN (Sc1ccc2c(c1)CCO2) [C@H] (CO) CCCCNC (=O) [C@@H] (Cc1cccc2ccccc12) NC (=O) N1CCOCC1*CC (C) CN (Sc1ccc2c(c1)OCCO2) [C@H] (CO) CCCCNC (=O) [C@@H] (Cc1cccc2ccccc12) NC (=O) N1CCOCC1*CC (C) CN ([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)NC(=O)N1CCOCC1) S (=O) (=O) c1ccc2c (c1) CCO2*Cc1c (O) cccc1C (=O) N [C@@H] (Cc1ccccc1Br) C (=O) NCCCC [C@@H] (CO) N (CC(C)C) S (=O) (=O) c1ccc (N) cc1*CC (C) CN ([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)NC(=O)c1cccc(=O)[nH]1) S (=O) (=O) c1ccc (N) cc1*Cc1ccccc1C [C@H] (NC(=O)c1cccnc1) C (=O) NCCCC [C@@H] (CO) N (CC(C)C) S (=O) (=O) c1ccc (N) cc1*O=C (O) CNC (=O) c1c (=O) oc (O) c2cc (Br) ccc12*C [C@H] (NC(=O)c1c(=O)oc(O)c2cccc(-c3cccc(C(F)(F)F)c3)c12) C (=O) O*Cc1ccccc1C [C@H] (NC(=O)c1cccc(C)c1O) C (=O) NCCCC [C@@H] (CO) N (CC(C)C) S (=O) (=O) c1ccc (N) cc1*COC (=O) N [C@@H] (CC1CCCCC1) C (=O) NCCCC [C@@H] (CO) N (CC(C)C) S (=O) (=O) c1ccc (N) cc1*CC (C) CN ([C@H](CO)CCCCNC(=O)[C@H](CC1CCCCC1)NC(=O)c1cccnc1) S (=O) (=O) c1ccc (N) cc1*Cc1ccc (C(=O)N[C@@H](CC2CCCCC2)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c2ccc(N)cc2) cn1*COC (=O) N [C@H] (C(=O)NCCCC[C@H](CO)N(CC(C)C)S(=O)(=O)c1cccc2cccnc12) C (c1ccccc1) c1ccccc1*CC (C) CN ([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Cl)NC(=O)c1ccncc1) S (=O) (=O) c1ccc (N) cc1*Cc1ncccc1C (=O) N [C@@H] (Cc1ccccc1Cl) C (=O) NCCCC [C@@H] (CO) N (CC(C)C) S (=O) (=O) c1ccc (N) cc1*CC (C) CN ([C@H](CO)CCCCNC(=O)[C@H](CC1=C(Br)CCC=C1)NC(=O)N1CCOCC1) S (=O) (=O) c1ccc2c (c1) OCCO2*COC (=O) N [C@H] (C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c1ccc2c(c1)CCO2) C (C1=CC=CCC1) c1ccccc1*CC (C) CN ([C@H](CO)CCCCNC(=O)[C@@H](NC(=O)N1CCOCC1)C(c1ccccc1)c1ccccc1) S (=O) (=O) c1ccc2c (c1) CCO2*COC (=O) N [C@H] (C(=O)NCCCC[C@H](CO)N(CC(C)C)S(=O)(=O)c1ccc2c(c1)N(C)CCO2) C (c1ccccc1) c1ccccc1*Cc1cccnc1C (=O) N [C@@H] (Cc1ccccc1Br) C (=O) NCCCC [C@@H] (CO) N (CC(C)C) S (=O) (=O) c1ccc (N) cc1*Cc1ccc (C(=O)N[C@@H](Cc2ccccc2Br)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c2ccc(N)cc2) cc1O*CC (C) CN ([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)NC(=O)OCc1ccncc1) S (=O) (=O) c1ccc (N) cc1*CC (C) CN ([C@H](CO)CCCCNC(=O)[C@H](Cc1ccc2ccccc2c1)NS(=O)(=O)c1ccc2c(c1)OCCC2C) S (=O) (=O) c1ccc (N) cc1*CCC (=O) NC (=O) N (C) CC (=O) N [C@@H] (Cc1ccc2ccccc2c1) C (=O) NCCCC [C@@H] (CO) N (CC(C)C) S (=O) (=O) c1ccc (N) cc1*CC (C) CN ([C@H](CO)CCCCNC(=O)[C@H](Cc1ccc2ccccc2c1)NCc1ccccn1) S (=O) (=O) c1ccc (N) cc1*CC (C) CN ([C@H](CO)CCCCNC(=O)[C@@H](NS(=O)(=O)c1cccs1)C(c1ccccc1)c1ccccc1) S (=O) (=O) c1ccc (N) cc1*CN [C@H] (C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1) C (c1ccccc1) C1C=CC=CC1*CC (C) CN ([C@H](CO)CCCCNC(=O)[C@@H](NC(=O)NCC1=CCCN=C1)C(c1ccccc1)c1ccccc1) S (=O) (=O) c1ccc (N) cc1*CC (C) CN ([C@H](CO)CCCCNC(=O)[C@@H](NC(=O)NCc1ccncc1)C(c1ccccc1)c1ccccc1) S (=O) (=O) c1ccc (N) cc1*Cc1ccc (C(=O)N[C@@H](Cc2ccccc2C)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c2ccc(N)cc2) cc1O*COC (=O) N [C@H] (C(=O)NCCCCC(C(N)=O)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1) C (c1ccccc1) c1ccccc1*COC (=O) N [C@H] (C(=O)NCCCC[C@@H](CO)N(Cc1cccnc1)S(=O)(=O)c1ccc(N)cc1) C (c1ccccc1) c1ccccc1*Cc1ncccc1C (=O) N [C@@H] (Cc1ccccc1Br) C (=O) NCCCC [C@@H] (CO) N (CC(C)C) S (=O) (=O) c1ccc (N) cc1*Cc1ccc (C(=O)N[C@@H](Cc2ccccc2Br)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c2ccc(N)cc2) cn1*CC (C) CN ([C@H](CO)CCCCNC(=O)[C@@H](Cc1ccccc1Br)NC(=O)c1ccc2c(c1)OCO2) S (=O) (=O) c1ccc (N) cc1*CC (C) CN ([C@H](CO)CCCCNC(=O)C(Cc1ccccc1Br)NC(=O)c1ccncc1) S (=O) (=O) c1ccc (N) cc1*CC (C) CN ([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)NC(=O)C1=NCC(C)N=C1) S (=O) (=O) c1ccc (N) cc1*CC (C) CN ([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)NC(=O)c1cnccn1) S (=O) (=O) c1ccc (N) cc1*CC (C) CN ([C@H](CO)CCCCNC(=O)[C@@H](Cc1ccccc1Br)NC(=O)c1ccccn1) S (=O) (=O) c1ccc (N) cc1*CC (C) CN ([C@H](CO)CCCCNC(=O)[C@@H](Cc1ccccc1Br)NC(=O)c1cccnc1) S (=O) (=O) c1ccc (N) cc1*COC (=O) N [C@H] (C(=O)NCCCC[C@H](C(N)=O)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1) C (c1ccccc1) c1ccccc1*CC (=O) N [C@H] (C(=O)NCCCCC(C(N)=O)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1) C (c1ccccc1) c1ccccc1*CC (C) CN (C(CCCCNC(=O)[C@H](CC1=C2C=CC=CC2CC=C1)NC(=O)N1CCOCC1)C(N)=O) S (=O) (=O) c1ccc (N) cc1*'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 10,  1,  ..., 18, 18,  4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 500\n",
    "eval_interval = 10\n",
    "learning_rate = 0.001\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "n_embd = 25\n",
    "n_head = 5\n",
    "n_layer = 6\n",
    "dropout = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMILESTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embd, n_head, n_layer, dropout):\n",
    "        super(SMILESTransformer, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, n_embd)\n",
    "        self.transformer = nn.Transformer(n_embd, n_head, n_layer, dropout=dropout)\n",
    "        self.fc = nn.Linear(n_embd, vocab_size)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.transformer(x, x)\n",
    "        x = self.fc(x)\n",
    "        x = self.log_softmax(x) \n",
    "        return x\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens, block_size):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :]  # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
    "        return idx\n",
    "    \n",
    "\n",
    "model = SMILESTransformer(vocab_size, n_embd, n_head, n_layer, dropout).to(device)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_loss():\n",
    "    losses = {}\n",
    "    for split in ['train', 'val']:\n",
    "        x, y = get_batch(split)\n",
    "        output = model(x)\n",
    "        loss = criterion(output.view(-1, vocab_size), y.view(-1))\n",
    "        losses[split] = loss.item()\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 3.1839, val loss 3.1272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/500 [00:02<02:01,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10: train loss 2.7049, val loss 2.6784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 20/500 [00:05<02:01,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 20: train loss 2.6624, val loss 2.6497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 30/500 [00:08<01:55,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 30: train loss 2.5833, val loss 2.5562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 40/500 [00:10<01:47,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 40: train loss 2.5420, val loss 2.4835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 50/500 [00:13<01:45,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 50: train loss 2.5233, val loss 2.4582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 60/500 [00:15<01:40,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 60: train loss 2.4745, val loss 2.4955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 70/500 [00:18<01:47,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 70: train loss 2.5236, val loss 2.4567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 80/500 [00:20<01:38,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 80: train loss 2.5188, val loss 2.4797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 90/500 [00:23<01:35,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 90: train loss 2.4894, val loss 2.5378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 100/500 [00:25<01:33,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 100: train loss 2.3853, val loss 2.3004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 110/500 [00:28<01:31,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 110: train loss 2.0373, val loss 1.9775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 120/500 [00:30<01:30,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 120: train loss 1.7490, val loss 1.7719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 130/500 [00:33<01:29,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 130: train loss 1.6053, val loss 1.6862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 140/500 [00:36<01:26,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 140: train loss 1.4933, val loss 1.6384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 150/500 [00:38<01:27,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 150: train loss 1.5133, val loss 1.5447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 160/500 [00:41<01:24,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 160: train loss 1.4973, val loss 1.4941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 170/500 [00:43<01:21,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 170: train loss 1.4381, val loss 1.7087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 180/500 [00:46<01:22,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 180: train loss 1.4703, val loss 1.4315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 190/500 [00:49<01:16,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 190: train loss 1.3867, val loss 1.3467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 200/500 [00:52<01:21,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 200: train loss 1.4353, val loss 1.4417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 210/500 [00:55<01:21,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 210: train loss 1.4929, val loss 1.5582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 220/500 [00:57<01:08,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 220: train loss 1.4241, val loss 1.7393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 230/500 [01:00<01:11,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 230: train loss 1.4000, val loss 1.3762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 240/500 [01:03<01:02,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 240: train loss 1.3503, val loss 1.4091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 250/500 [01:05<00:57,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 250: train loss 1.3450, val loss 1.3789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 260/500 [01:08<00:58,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 260: train loss 1.4279, val loss 1.2266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 270/500 [01:11<01:00,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 270: train loss 1.2958, val loss 1.3409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 280/500 [01:13<00:55,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 280: train loss 1.3467, val loss 1.4682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 290/500 [01:16<00:51,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 290: train loss 1.3709, val loss 1.4261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 300/500 [01:19<00:54,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 300: train loss 1.4625, val loss 1.5101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 310/500 [01:22<00:51,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 310: train loss 1.2201, val loss 1.2456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 320/500 [01:25<00:49,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 320: train loss 1.2856, val loss 1.3695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 330/500 [01:28<00:51,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 330: train loss 1.3889, val loss 1.3995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 340/500 [01:31<00:41,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 340: train loss 1.3119, val loss 1.3554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 350/500 [01:33<00:39,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 350: train loss 1.3419, val loss 1.4947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 360/500 [01:36<00:39,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 360: train loss 1.4296, val loss 1.5031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 370/500 [01:39<00:33,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 370: train loss 1.3687, val loss 1.4344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 380/500 [01:42<00:30,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 380: train loss 1.2812, val loss 1.5541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 390/500 [01:45<00:28,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 390: train loss 1.3938, val loss 1.4578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 400/500 [01:47<00:25,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 400: train loss 1.3038, val loss 1.5541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 410/500 [01:50<00:23,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 410: train loss 1.3716, val loss 1.4596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 420/500 [01:53<00:18,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 420: train loss 1.3856, val loss 1.3828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 430/500 [01:55<00:15,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 430: train loss 1.3847, val loss 1.4246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 440/500 [01:57<00:14,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 440: train loss 1.3183, val loss 1.3955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 450/500 [02:00<00:12,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 450: train loss 1.2984, val loss 1.5664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 460/500 [02:03<00:09,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 460: train loss 1.3368, val loss 1.3275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 470/500 [02:06<00:07,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 470: train loss 1.3594, val loss 1.3879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 480/500 [02:08<00:04,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 480: train loss 1.3067, val loss 1.4637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 490/500 [02:11<00:02,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 490: train loss 1.3298, val loss 1.4253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 499/500 [02:13<00:00,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 499: train loss 1.4188, val loss 1.3759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:13<00:00,  3.73it/s]\n"
     ]
    }
   ],
   "source": [
    "for iter in tqdm(range(max_iters)):\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # Sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # Evaluate the loss\n",
    "    output = model(xb)\n",
    "    loss = criterion(output.view(-1, vocab_size), yb.view(-1))\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "generated_sequence = model.generate(context, max_new_tokens=500, block_size=block_size)\n",
    "sequence = decode(generated_sequence[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'CC@H](=SH](C',\n",
       " 'S)',\n",
       " 'S([(c1c1ccc1cc1C)',\n",
       " '([l)',\n",
       " 'C@@@H]([)((=O)(C(=O@H](=O)C',\n",
       " '(=O)O@@H](COC(N',\n",
       " '(CCCcc1ccc1',\n",
       " 'c1C@l)N',\n",
       " '(=O)C',\n",
       " '(S(]([C)',\n",
       " '[C-c1c1BnCCCCCO)',\n",
       " '(C1C',\n",
       " 'CC[)C',\n",
       " '[CC)(C',\n",
       " '(NCCO)',\n",
       " '(CO)',\n",
       " '(=OCCC[Ccc(c1ccc2c1ccc2ccccl)',\n",
       " '(=NCCcc=O)',\n",
       " '(CC(NCNCC(',\n",
       " '(=O)SC)',\n",
       " 'CCC@H](=OCO)',\n",
       " 'CNCC@(=NC',\n",
       " 'c',\n",
       " 'c',\n",
       " '(ccc',\n",
       " 'CCcc(CO)NC',\n",
       " '((c2c1',\n",
       " 'CCC',\n",
       " '(c(c1cccc)1cccccc1)CC(c1c1cc1c',\n",
       " '(=BCN',\n",
       " 'ccccn1c1c1C',\n",
       " 'S',\n",
       " '(NCO)N',\n",
       " 'N)r1)',\n",
       " 'CO)r([)cccc)(CC',\n",
       " '@H](=O)',\n",
       " '(C@H](=OC',\n",
       " '(=O)',\n",
       " '(c1)',\n",
       " '(cccc([Cc2',\n",
       " '(=O)',\n",
       " '(cc1cccc1)',\n",
       " '(N)cccccc1',\n",
       " 's)',\n",
       " 'NC',\n",
       " '(ccc',\n",
       " 'S)',\n",
       " 'cccc',\n",
       " '(=O)cc(CC)([CCO)',\n",
       " '(C2c',\n",
       " 'NNCNN',\n",
       " 'N(=OCC@H](S(CCO)11',\n",
       " 'CC',\n",
       " 'ccc1c1']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = sequence.split(' ')\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CC@H](=SH](C',\n",
       " 'S([(c1c1ccc1cc1C)',\n",
       " '([l)',\n",
       " 'C@@@H]([)((=O)(C(=O@H](=O)C',\n",
       " '(=O)O@@H](COC(N',\n",
       " '(CCCcc1ccc1',\n",
       " 'c1C@l)N',\n",
       " '(=O)C',\n",
       " '(S(]([C)',\n",
       " '[C-c1c1BnCCCCCO)',\n",
       " '(C1C',\n",
       " 'CC[)C',\n",
       " '[CC)(C',\n",
       " '(NCCO)',\n",
       " '(CO)',\n",
       " '(=OCCC[Ccc(c1ccc2c1ccc2ccccl)',\n",
       " '(=NCCcc=O)',\n",
       " '(CC(NCNCC(',\n",
       " '(=O)SC)',\n",
       " 'CCC@H](=OCO)',\n",
       " 'CNCC@(=NC',\n",
       " '(ccc',\n",
       " 'CCcc(CO)NC',\n",
       " '((c2c1',\n",
       " 'CCC',\n",
       " '(c(c1cccc)1cccccc1)CC(c1c1cc1c',\n",
       " '(=BCN',\n",
       " 'ccccn1c1c1C',\n",
       " '(NCO)N',\n",
       " 'N)r1)',\n",
       " 'CO)r([)cccc)(CC',\n",
       " '@H](=O)',\n",
       " '(C@H](=OC',\n",
       " '(=O)',\n",
       " '(c1)',\n",
       " '(cccc([Cc2',\n",
       " '(=O)',\n",
       " '(cc1cccc1)',\n",
       " '(N)cccccc1',\n",
       " '(ccc',\n",
       " 'cccc',\n",
       " '(=O)cc(CC)([CCO)',\n",
       " '(C2c',\n",
       " 'NNCNN',\n",
       " 'N(=OCC@H](S(CCO)11',\n",
       " 'ccc1c1']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = [s for s in sequence if len(s) > 2]\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[03:36:58] SMILES Parse Error: syntax error while parsing: CC@H](=SH](C\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES 'CC@H](=SH](C' for input: 'CC@H](=SH](C'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: S([(c1c1ccc1cc1C)\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES 'S([(c1c1ccc1cc1C)' for input: 'S([(c1c1ccc1cc1C)'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: ([l)\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '([l)' for input: '([l)'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: C@@@H]([)((=O)(C(=O@H](=O)C\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES 'C@@@H]([)((=O)(C(=O@H](=O)C' for input: 'C@@@H]([)((=O)(C(=O@H](=O)C'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: (=O)O@@H](COC(N\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '(=O)O@@H](COC(N' for input: '(=O)O@@H](COC(N'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: (CCCcc1ccc1\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '(CCCcc1ccc1' for input: '(CCCcc1ccc1'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: c1C@l)N\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES 'c1C@l)N' for input: 'c1C@l)N'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: (=O)C\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '(=O)C' for input: '(=O)C'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: (S(]([C)\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '(S(]([C)' for input: '(S(]([C)'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: [C-c1c1BnCCCCCO)\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '[C-c1c1BnCCCCCO)' for input: '[C-c1c1BnCCCCCO)'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: (C1C\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '(C1C' for input: '(C1C'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: CC[)C\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES 'CC[)C' for input: 'CC[)C'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: [CC)(C\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '[CC)(C' for input: '[CC)(C'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: (NCCO)\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '(NCCO)' for input: '(NCCO)'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: (CO)\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '(CO)' for input: '(CO)'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: (=OCCC[Ccc(c1ccc2c1ccc2ccccl)\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '(=OCCC[Ccc(c1ccc2c1ccc2ccccl)' for input: '(=OCCC[Ccc(c1ccc2c1ccc2ccccl)'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: (=NCCcc=O)\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '(=NCCcc=O)' for input: '(=NCCcc=O)'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: (CC(NCNCC(\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '(CC(NCNCC(' for input: '(CC(NCNCC('\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: (=O)SC)\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '(=O)SC)' for input: '(=O)SC)'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: CCC@H](=OCO)\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES 'CCC@H](=OCO)' for input: 'CCC@H](=OCO)'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: CNCC@(=NC\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES 'CNCC@(=NC' for input: 'CNCC@(=NC'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: (ccc\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '(ccc' for input: '(ccc'\n",
      "[03:36:58] non-ring atom 2 marked aromatic\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: ((c2c1\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '((c2c1' for input: '((c2c1'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: (c(c1cccc)1cccccc1)CC(c1c1cc1c\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '(c(c1cccc)1cccccc1)CC(c1c1cc1c' for input: '(c(c1cccc)1cccccc1)CC(c1c1cc1c'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: (=BCN\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '(=BCN' for input: '(=BCN'\n",
      "[03:36:58] SMILES Parse Error: ring closure 1 duplicates bond between atom 4 and atom 5 for input: 'ccccn1c1c1C'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: (NCO)N\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '(NCO)N' for input: '(NCO)N'\n",
      "[03:36:58] SMILES Parse Error: extra close parentheses while parsing: N)r1)\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES 'N)r1)' for input: 'N)r1)'\n",
      "[03:36:58] SMILES Parse Error: extra close parentheses while parsing: CO)r([)cccc)(CC\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES 'CO)r([)cccc)(CC' for input: 'CO)r([)cccc)(CC'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: @H](=O)\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '@H](=O)' for input: '@H](=O)'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: (C@H](=OC\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '(C@H](=OC' for input: '(C@H](=OC'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: (=O)\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '(=O)' for input: '(=O)'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: (c1)\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '(c1)' for input: '(c1)'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: (cccc([Cc2\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '(cccc([Cc2' for input: '(cccc([Cc2'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: (=O)\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '(=O)' for input: '(=O)'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: (cc1cccc1)\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '(cc1cccc1)' for input: '(cc1cccc1)'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: (N)cccccc1\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '(N)cccccc1' for input: '(N)cccccc1'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: (ccc\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '(ccc' for input: '(ccc'\n",
      "[03:36:58] non-ring atom 0 marked aromatic\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: (=O)cc(CC)([CCO)\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '(=O)cc(CC)([CCO)' for input: '(=O)cc(CC)([CCO)'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: (C2c\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES '(C2c' for input: '(C2c'\n",
      "[03:36:58] SMILES Parse Error: syntax error while parsing: N(=OCC@H](S(CCO)11\n",
      "[03:36:58] SMILES Parse Error: Failed parsing SMILES 'N(=OCC@H](S(CCO)11' for input: 'N(=OCC@H](S(CCO)11'\n",
      "[03:36:58] SMILES Parse Error: ring closure 1 duplicates bond between atom 2 and atom 3 for input: 'ccc1c1'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "mols = [Chem.MolFromSmiles(s) for s in sequence]\n",
    "Draw.MolsToGridImage(mols, molsPerRow=5, subImgSize=(200, 200), legends=[str(i) for i in range(len(mols))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
