{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2445\n",
      "0     CC(C)CN(Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C...\n",
      "1     CC(C)CN(Sc1ccc2c(c1)OCCO2)[C@H](CO)CCCCNC(=O)[...\n",
      "2     CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "3     Cc1c(O)cccc1C(=O)N[C@@H](Cc1ccccc1Br)C(=O)NCCC...\n",
      "4     CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "5     Cc1ccccc1C[C@H](NC(=O)c1cccnc1)C(=O)NCCCC[C@@H...\n",
      "6                O=C(O)CNC(=O)c1c(=O)oc(O)c2cc(Br)ccc12\n",
      "7     C[C@H](NC(=O)c1c(=O)oc(O)c2cccc(-c3cccc(C(F)(F...\n",
      "8     Cc1ccccc1C[C@H](NC(=O)c1cccc(C)c1O)C(=O)NCCCC[...\n",
      "9     COC(=O)N[C@@H](CC1CCCCC1)C(=O)NCCCC[C@@H](CO)N...\n",
      "10    CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](CC1CCCCC1)NC(...\n",
      "11    Cc1ccc(C(=O)N[C@@H](CC2CCCCC2)C(=O)NCCCC[C@@H]...\n",
      "12    COC(=O)N[C@H](C(=O)NCCCC[C@H](CO)N(CC(C)C)S(=O...\n",
      "13    CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Cl)N...\n",
      "14    Cc1ncccc1C(=O)N[C@@H](Cc1ccccc1Cl)C(=O)NCCCC[C...\n",
      "15    CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](CC1=C(Br)CCC=...\n",
      "16    COC(=O)N[C@H](C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=...\n",
      "17    CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](NC(=O)N1CCOC...\n",
      "18    COC(=O)N[C@H](C(=O)NCCCC[C@H](CO)N(CC(C)C)S(=O...\n",
      "19    Cc1cccnc1C(=O)N[C@@H](Cc1ccccc1Br)C(=O)NCCCC[C...\n",
      "20    Cc1ccc(C(=O)N[C@@H](Cc2ccccc2Br)C(=O)NCCCC[C@@...\n",
      "21    CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "22    CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccc2ccccc2...\n",
      "23    CCC(=O)NC(=O)N(C)CC(=O)N[C@@H](Cc1ccc2ccccc2c1...\n",
      "24    CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccc2ccccc2...\n",
      "25    CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](NS(=O)(=O)c1...\n",
      "26    CN[C@H](C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)...\n",
      "27    CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](NC(=O)NCC1=C...\n",
      "28    CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](NC(=O)NCc1cc...\n",
      "29    Cc1ccc(C(=O)N[C@@H](Cc2ccccc2C)C(=O)NCCCC[C@@H...\n",
      "30    COC(=O)N[C@H](C(=O)NCCCCC(C(N)=O)N(CC(C)C)S(=O...\n",
      "31    COC(=O)N[C@H](C(=O)NCCCC[C@@H](CO)N(Cc1cccnc1)...\n",
      "32    Cc1ncccc1C(=O)N[C@@H](Cc1ccccc1Br)C(=O)NCCCC[C...\n",
      "33    Cc1ccc(C(=O)N[C@@H](Cc2ccccc2Br)C(=O)NCCCC[C@@...\n",
      "34    CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](Cc1ccccc1Br)...\n",
      "35    CC(C)CN([C@H](CO)CCCCNC(=O)C(Cc1ccccc1Br)NC(=O...\n",
      "36    CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "37    CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "38    CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](Cc1ccccc1Br)...\n",
      "39    CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](Cc1ccccc1Br)...\n",
      "40    COC(=O)N[C@H](C(=O)NCCCC[C@H](C(N)=O)N(CC(C)C)...\n",
      "41    CC(=O)N[C@H](C(=O)NCCCCC(C(N)=O)N(CC(C)C)S(=O)...\n",
      "42    CC(C)CN(C(CCCCNC(=O)[C@H](CC1=C2C=CC=CC2CC=C1)...\n",
      "Name: canonical_smiles, dtype: object\n",
      "\n",
      " (),-.0123456789:=@BCFHNOS[]_abcdeijlmnoprsty\n",
      "46\n",
      "[21, 21, 25]\n",
      "CCO\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('hiv_protease_inhibitors_data_chemlb_full.csv')\n",
    "\n",
    "smiles = data['canonical_smiles']\n",
    "#print(len(smiles))\n",
    "\n",
    "text = str(smiles)\n",
    "print(len(text))\n",
    "print(text)\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)\n",
    "\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "print(encode('CCO'))\n",
    "print(decode(encode('CCO')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CC(C)CN(Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc12)NC(=O)N1CCOCC1', 'CC(C)CN(Sc1ccc2c(c1)OCCO2)[C@H](CO)CCCCNC(=O)[C@@H](Cc1cccc2ccccc12)NC(=O)N1CCOCC1', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)NC(=O)N1CCOCC1)S(=O)(=O)c1ccc2c(c1)CCO2', 'Cc1c(O)cccc1C(=O)N[C@@H](Cc1ccccc1Br)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)NC(=O)c1cccc(=O)[nH]1)S(=O)(=O)c1ccc(N)cc1', 'Cc1ccccc1C[C@H](NC(=O)c1cccnc1)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1', 'O=C(O)CNC(=O)c1c(=O)oc(O)c2cc(Br)ccc12', 'C[C@H](NC(=O)c1c(=O)oc(O)c2cccc(-c3cccc(C(F)(F)F)c3)c12)C(=O)O', 'Cc1ccccc1C[C@H](NC(=O)c1cccc(C)c1O)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1', 'COC(=O)N[C@@H](CC1CCCCC1)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](CC1CCCCC1)NC(=O)c1cccnc1)S(=O)(=O)c1ccc(N)cc1', 'Cc1ccc(C(=O)N[C@@H](CC2CCCCC2)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c2ccc(N)cc2)cn1', 'COC(=O)N[C@H](C(=O)NCCCC[C@H](CO)N(CC(C)C)S(=O)(=O)c1cccc2cccnc12)C(c1ccccc1)c1ccccc1', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Cl)NC(=O)c1ccncc1)S(=O)(=O)c1ccc(N)cc1', 'Cc1ncccc1C(=O)N[C@@H](Cc1ccccc1Cl)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](CC1=C(Br)CCC=C1)NC(=O)N1CCOCC1)S(=O)(=O)c1ccc2c(c1)OCCO2', 'COC(=O)N[C@H](C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c1ccc2c(c1)CCO2)C(C1=CC=CCC1)c1ccccc1', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](NC(=O)N1CCOCC1)C(c1ccccc1)c1ccccc1)S(=O)(=O)c1ccc2c(c1)CCO2', 'COC(=O)N[C@H](C(=O)NCCCC[C@H](CO)N(CC(C)C)S(=O)(=O)c1ccc2c(c1)N(C)CCO2)C(c1ccccc1)c1ccccc1', 'Cc1cccnc1C(=O)N[C@@H](Cc1ccccc1Br)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1', 'Cc1ccc(C(=O)N[C@@H](Cc2ccccc2Br)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c2ccc(N)cc2)cc1O', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)NC(=O)OCc1ccncc1)S(=O)(=O)c1ccc(N)cc1', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccc2ccccc2c1)NS(=O)(=O)c1ccc2c(c1)OCCC2C)S(=O)(=O)c1ccc(N)cc1', 'CCC(=O)NC(=O)N(C)CC(=O)N[C@@H](Cc1ccc2ccccc2c1)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccc2ccccc2c1)NCc1ccccn1)S(=O)(=O)c1ccc(N)cc1', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](NS(=O)(=O)c1cccs1)C(c1ccccc1)c1ccccc1)S(=O)(=O)c1ccc(N)cc1', 'CN[C@H](C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1)C(c1ccccc1)C1C=CC=CC1', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](NC(=O)NCC1=CCCN=C1)C(c1ccccc1)c1ccccc1)S(=O)(=O)c1ccc(N)cc1', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](NC(=O)NCc1ccncc1)C(c1ccccc1)c1ccccc1)S(=O)(=O)c1ccc(N)cc1', 'Cc1ccc(C(=O)N[C@@H](Cc2ccccc2C)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c2ccc(N)cc2)cc1O', 'COC(=O)N[C@H](C(=O)NCCCCC(C(N)=O)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1)C(c1ccccc1)c1ccccc1', 'COC(=O)N[C@H](C(=O)NCCCC[C@@H](CO)N(Cc1cccnc1)S(=O)(=O)c1ccc(N)cc1)C(c1ccccc1)c1ccccc1', 'Cc1ncccc1C(=O)N[C@@H](Cc1ccccc1Br)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1', 'Cc1ccc(C(=O)N[C@@H](Cc2ccccc2Br)C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O)(=O)c2ccc(N)cc2)cn1', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](Cc1ccccc1Br)NC(=O)c1ccc2c(c1)OCO2)S(=O)(=O)c1ccc(N)cc1', 'CC(C)CN([C@H](CO)CCCCNC(=O)C(Cc1ccccc1Br)NC(=O)c1ccncc1)S(=O)(=O)c1ccc(N)cc1', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)NC(=O)C1=NCC(C)N=C1)S(=O)(=O)c1ccc(N)cc1', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)NC(=O)c1cnccn1)S(=O)(=O)c1ccc(N)cc1', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](Cc1ccccc1Br)NC(=O)c1ccccn1)S(=O)(=O)c1ccc(N)cc1', 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](Cc1ccccc1Br)NC(=O)c1cccnc1)S(=O)(=O)c1ccc(N)cc1', 'COC(=O)N[C@H](C(=O)NCCCC[C@H](C(N)=O)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1)C(c1ccccc1)c1ccccc1', 'CC(=O)N[C@H](C(=O)NCCCCC(C(N)=O)N(CC(C)C)S(=O)(=O)c1ccc(N)cc1)C(c1ccccc1)c1ccccc1', 'CC(C)CN(C(CCCCNC(=O)[C@H](CC1=C2C=CC=CC2CC=C1)NC(=O)N1CCOCC1)C(N)=O)S(=O)(=O)c1ccc(N)cc1']\n"
     ]
    }
   ],
   "source": [
    "type(smiles)\n",
    "l_smile = print(list(smiles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.207278 M parameters\n",
      "step 0: train loss 4.0509, val loss 4.0302\n",
      "step 100: train loss 1.1122, val loss 1.9270\n",
      "step 200: train loss 0.7895, val loss 1.8587\n",
      "step 300: train loss 0.6017, val loss 1.8059\n",
      "step 400: train loss 0.5048, val loss 1.7821\n",
      "step 500: train loss 0.4382, val loss 1.8112\n",
      "step 600: train loss 0.3777, val loss 1.8533\n",
      "step 700: train loss 0.3655, val loss 1.8897\n",
      "step 800: train loss 0.3442, val loss 2.0771\n",
      "step 900: train loss 0.2974, val loss 2.0155\n",
      "step 1000: train loss 0.2819, val loss 2.1691\n",
      "step 1100: train loss 0.2774, val loss 2.1981\n",
      "step 1200: train loss 0.2510, val loss 2.2761\n",
      "step 1300: train loss 0.2511, val loss 2.2406\n",
      "step 1400: train loss 0.2258, val loss 2.3038\n",
      "step 1500: train loss 0.2282, val loss 2.3440\n",
      "step 1600: train loss 0.2186, val loss 2.3322\n",
      "step 1700: train loss 0.2076, val loss 2.2826\n",
      "step 1800: train loss 0.2085, val loss 2.3459\n",
      "step 1900: train loss 0.2053, val loss 2.2555\n",
      "step 2000: train loss 0.2061, val loss 2.4510\n",
      "step 2100: train loss 0.1967, val loss 2.5242\n",
      "step 2200: train loss 0.1935, val loss 2.3835\n",
      "step 2300: train loss 0.2048, val loss 2.4352\n",
      "step 2400: train loss 0.1906, val loss 2.3927\n",
      "step 2500: train loss 0.1923, val loss 2.3257\n",
      "step 2600: train loss 0.1901, val loss 2.5915\n",
      "step 2700: train loss 0.1920, val loss 2.4180\n",
      "step 2800: train loss 0.1869, val loss 2.4573\n",
      "step 2900: train loss 0.1885, val loss 2.5490\n",
      "step 3000: train loss 0.1822, val loss 2.5477\n",
      "step 3100: train loss 0.1796, val loss 2.5376\n",
      "step 3200: train loss 0.1862, val loss 2.5876\n",
      "step 3300: train loss 0.1832, val loss 2.6389\n",
      "step 3400: train loss 0.1786, val loss 2.5359\n",
      "step 3500: train loss 0.1778, val loss 2.4869\n",
      "step 3600: train loss 0.1798, val loss 2.5707\n",
      "step 3700: train loss 0.1776, val loss 2.5500\n",
      "step 3800: train loss 0.1783, val loss 2.5565\n",
      "step 3900: train loss 0.1813, val loss 2.5182\n",
      "step 4000: train loss 0.1741, val loss 2.5552\n",
      "step 4100: train loss 0.1733, val loss 2.5614\n",
      "step 4200: train loss 0.1844, val loss 2.7041\n",
      "step 4300: train loss 0.1790, val loss 2.5615\n",
      "step 4400: train loss 0.1784, val loss 2.6965\n",
      "step 4500: train loss 0.1711, val loss 2.6106\n",
      "step 4600: train loss 0.1734, val loss 2.6004\n",
      "step 4700: train loss 0.1741, val loss 2.5597\n",
      "step 4800: train loss 0.1743, val loss 2.6159\n",
      "step 4900: train loss 0.1711, val loss 2.6443\n",
      "step 4999: train loss 0.1716, val loss 2.6329\n",
      "\n",
      "38    CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "39    Cc1c(C(=O)N[C@@H](Cc2cccCC(=O)NCCCC[C@@H...\n",
      "30    COC(=O)N[C@H](C(=O)NCCCCC(C(N)=O)N(CC(C)C)S(=O...\n",
      "31    COC(=O)N[C@H](C(=O)NCCCCC(C(N)=O)N(CC(C)C)S(=O...\n",
      "31    COC(=O)N[C@H](C(=O)NCCCC[C@H](CO)N(Cc1cccnc1)...\n",
      "32    Cc1ncccc1C(=O)N[C@@H](Cc1ccccc1Br)C(=O)NCCCC[C...\n",
      "20    Cc1ccc(C(=O)N[C@@H](Cc2ccccc2Br)C(=O)NCCCC[C@@...\n",
      "34    CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](NC(=O)NCC1=C...\n",
      "28    CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "22    CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "5     Cc1ccccc1C[C@H](NC(=O)c1cccnc1)C(=O)NCCCC[C@@H...\n",
      "6                O=C(O)CNC(=O)c1c(=O)oc(O)c2c(Br)ccc12\n",
      "7     C[C@H](NC(=O)c1c(=O)oc(O)c2cccc(-c3cccc(C(F)(F...\n",
      "8     Cc1ccccc1C[C@H](NC(=O)c1cccnc1)C(=O)NCCCC[C@@H...\n",
      "6                O=C(O)CNC(=O)c1c(=O)oc(O)c2cc(Br)ccc12\n",
      "7     C[C@H](N...\n",
      "21    CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccc2ccccc2...\n",
      "23    CCC(=O)NC(=O)N(C)CC(=O)N[C@@H](Cc1ccc2ccccc2c1...\n",
      "24    CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](NS(=O)(=O)c1...\n",
      "26    CN[C@H](C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=...\n",
      "17    CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccc2ccccc2...\n",
      "25    CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](NS(=O)(=O)c1...\n",
      "26    CN[C@H](C(=O)NCCCC[C@@H](CO)N(Cc1cccnc1)...\n",
      "32    Cc1ncccc1C(=O)N[C@@H](Cc1ccccc1Br)C(=O)NCCCC[C...\n",
      "20    Cc1ccc(C(=O)N[C@@H](Cc2ccccc2C)C(=O)NCCCC[C@@H...\n",
      "30    COC(=O)N[C@H](C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O...\n",
      "12    COC(=O)N[C@H](C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=...\n",
      "17    CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "22    CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](NC(=O)N1CCOC...\n",
      "18    COC(=O)N[C@H](C(=O)NCCCCC(C(N)=O)N(CC(C)C)S(=O...\n",
      "31    COC(=O)N[C@H](C(=O)NCCCCC(C(N)=O)N(CC(C)C)S(=O...\n",
      "31    COC(=O)N[C@H](C(=O)NCCCCC(C(N)=O)N(CC(C)C)S(=O...\n",
      "31    COC(=O)N[C@H](C(=O)NCCCC[C@H](CO)N(CC(C)C)S(=O...\n",
      "19    Cc1cccnc1C(=O)N[C@@H](Cc1ccccc1Cl)C(=O)NCCCC[C...\n",
      "13    Cc1ccc(C(=O)N[C@@H](Cc2ccccc2C)OC(=O)NCCCC[C@@...\n",
      "21    CC(C)CN([C@H](CO)CCCCNC(=O)C(Cc1ccccc1Br)NC(=O...\n",
      "36    CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ------------\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "# super simple bigram model\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = decode(m.generate(context, max_new_tokens=2000)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "36    CC(C)CN(Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[...\n",
      "2     CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1cc\n"
     ]
    }
   ],
   "source": [
    "print(val[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[21:21:41] SMILES Parse Error: syntax error while parsing: 36\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES '\n",
      "36' for input: '\n",
      "36'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: CC(C)CN(Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[...\n",
      "2\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'CC(C)CN(Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[...\n",
      "2' for input: 'CC(C)CN(Sc1ccc2c(c1)CCO2)[C@H](CO)CCCCNC(=O)[...\n",
      "2'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)...\n",
      "39\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)...\n",
      "39' for input: 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)...\n",
      "39'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccc2ccccc2...\n",
      "23\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccc2ccccc2...\n",
      "23' for input: 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccc2ccccc2...\n",
      "23'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: CCC(=O)NC(=O)N(C)CC(=O)N[C@@H](Cc1ccc2cc1...\n",
      "29\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'CCC(=O)NC(=O)N(C)CC(=O)N[C@@H](Cc1ccc2cc1...\n",
      "29' for input: 'CCC(=O)NC(=O)N(C)CC(=O)N[C@@H](Cc1ccc2cc1...\n",
      "29'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccc2ccccc2...\n",
      "25\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccc2ccccc2...\n",
      "25' for input: 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccc2ccccc2...\n",
      "25'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](CC1=C(Br)CCC=...\n",
      "16\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](CC1=C(Br)CCC=...\n",
      "16' for input: 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](CC1=C(Br)CCC=...\n",
      "16'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: COC(=O)N[C@H](C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=...\n",
      "17\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'COC(=O)N[C@H](C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=...\n",
      "17' for input: 'COC(=O)N[C@H](C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=...\n",
      "17'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccc2ccccc2...\n",
      "25)C(=O)NCCCCO2)[C@@...\n",
      "22\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccc2ccccc2...\n",
      "25)C(=O)NCCCCO2)[C@@...\n",
      "22' for input: 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccc2ccccc2...\n",
      "25)C(=O)NCCCCO2)[C@@...\n",
      "22'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "5\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "5' for input: 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "5'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: Cc1ccccc1C[C@H](NC(=O)c1cccnc1)C(=O)NCCCC[C@@H...\n",
      "6\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'Cc1ccccc1C[C@H](NC(=O)c1cccnc1)C(=O)NCCCC[C@@H...\n",
      "6' for input: 'Cc1ccccc1C[C@H](NC(=O)c1cccnc1)C(=O)NCCCC[C@@H...\n",
      "6'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: C[C@H](NC(=O)c1c(=O)oc(O)c2cccc(-c3cccc(C(F)(=O)NCCCC[C@@H...\n",
      "30\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'C[C@H](NC(=O)c1c(=O)oc(O)c2cccc(-c3cccc(C(F)(=O)NCCCC[C@@H...\n",
      "30' for input: 'C[C@H](NC(=O)c1c(=O)oc(O)c2cccc(-c3cccc(C(F)(=O)NCCCC[C@@H...\n",
      "30'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: COC(=O)N[C@H](C(=O)NCCCCC(C(N(=O)N(CC(C)C)S(=O)(=O...\n",
      "27\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'COC(=O)N[C@H](C(=O)NCCCCC(C(N(=O)N(CC(C)C)S(=O)(=O...\n",
      "27' for input: 'COC(=O)N[C@H](C(=O)NCCCCC(C(N(=O)N(CC(C)C)S(=O)(=O...\n",
      "27'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](NC(=O)N1CCOC...\n",
      "18\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](NC(=O)N1CCOC...\n",
      "18' for input: 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](NC(=O)N1CCOC...\n",
      "18'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: COC(=O)N[C@H](C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O...\n",
      "13\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'COC(=O)N[C@H](C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O...\n",
      "13' for input: 'COC(=O)N[C@H](C(=O)NCCCC[C@@H](CO)N(CC(C)C)S(=O...\n",
      "13'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccc2ccccc2...\n",
      "25\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccc2ccccc2...\n",
      "25' for input: 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccc2ccccc2...\n",
      "25'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](Cc1ccccc1Br)...\n",
      "35\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](Cc1ccccc1Br)...\n",
      "35' for input: 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](Cc1ccccc1Br)...\n",
      "35'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](CC1=C(Br)CCC=...\n",
      "16\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](CC1=C(Br)CCC=...\n",
      "16' for input: 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](CC1=C(Br)CCC=...\n",
      "16'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: COC(=O)N[C@H](C(=O)NCCCCC(C(N)=O)N(CC(C)C)S(=O...\n",
      "31\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'COC(=O)N[C@H](C(=O)NCCCCC(C(N)=O)N(CC(C)C)S(=O...\n",
      "31' for input: 'COC(=O)N[C@H](C(=O)NCCCCC(C(N)=O)N(CC(C)C)S(=O...\n",
      "31'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: COC(=O)N[C@H](C(=O)NCCCCC(C(N)=O)N(CC(C)C)S(=O...\n",
      "31\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'COC(=O)N[C@H](C(=O)NCCCCC(C(N)=O)N(CC(C)C)S(=O...\n",
      "31' for input: 'COC(=O)N[C@H](C(=O)NCCCCC(C(N)=O)N(CC(C)C)S(=O...\n",
      "31'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: COC(=O)N[C@H](C(=O)NCCCCC(C(N)=O)N(CC(C)C)S(=O...\n",
      "312\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'COC(=O)N[C@H](C(=O)NCCCCC(C(N)=O)N(CC(C)C)S(=O...\n",
      "312' for input: 'COC(=O)N[C@H](C(=O)NCCCCC(C(N)=O)N(CC(C)C)S(=O...\n",
      "312'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: COC(=O)N[C@H](C(=O)NCCCC[C@H](CO)N(CC(C)C)S(=O...\n",
      "19\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'COC(=O)N[C@H](C(=O)NCCCC[C@H](CO)N(CC(C)C)S(=O...\n",
      "19' for input: 'COC(=O)N[C@H](C(=O)NCCCC[C@H](CO)N(CC(C)C)S(=O...\n",
      "19'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: Cc1cccnc1C(=O)N[C@@H](Cc1ccccc1Br)C(=O)NCCCC[C...\n",
      "20\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'Cc1cccnc1C(=O)N[C@@H](Cc1ccccc1Br)C(=O)NCCCC[C...\n",
      "20' for input: 'Cc1cccnc1C(=O)N[C@@H](Cc1ccccc1Br)C(=O)NCCCC[C...\n",
      "20'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: Cc1ccc(C(=O)N[C@@H](Cc2ccccc2Br)C(=O)NCCCC[C@@...\n",
      "21\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'Cc1ccc(C(=O)N[C@@H](Cc2ccccc2Br)C(=O)NCCCC[C@@...\n",
      "21' for input: 'Cc1ccc(C(=O)N[C@@H](Cc2ccccc2Br)C(=O)NCCCC[C@@...\n",
      "21'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "38\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "38' for input: 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "38'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "38\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "38' for input: 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "38'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: CC(C)CN([C@H](CO)CCCCNC(=O)C(Cc1ccccc1Br)NC(=O...\n",
      "36\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'CC(C)CN([C@H](CO)CCCCNC(=O)C(Cc1ccccc1Br)NC(=O...\n",
      "36' for input: 'CC(C)CN([C@H](CO)CCCCNC(=O)C(Cc1ccccc1Br)NC(=O...\n",
      "36'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](NC(=O)N1CCOC...\n",
      "18\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](NC(=O)N1CCOC...\n",
      "18' for input: 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](NC(=O)N1CCOC...\n",
      "18'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: COC(=O)N[C@H](C(=O)NCCCCC(C(N)=O)N(CC(C)C)S(=...\n",
      "27\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'COC(=O)N[C@H](C(=O)NCCCCC(C(N)=O)N(CC(C)C)S(=...\n",
      "27' for input: 'COC(=O)N[C@H](C(=O)NCCCCC(C(N)=O)N(CC(C)C)S(=...\n",
      "27'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "3\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "3' for input: 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "3'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "38\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "38' for input: 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "38'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](NC(=O)NCc1cc...\n",
      "29\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](NC(=O)NCc1cc...\n",
      "29' for input: 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](NC(=O)NCc1cc...\n",
      "29'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: Cc1ccc(C(=O)N[C@@H](Cc2ccccc2Br)C(=O)NCCCC[C@@...\n",
      "21\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'Cc1ccc(C(=O)N[C@@H](Cc2ccccc2Br)C(=O)NCCCC[C@@...\n",
      "21' for input: 'Cc1ccc(C(=O)N[C@@H](Cc2ccccc2Br)C(=O)NCCCC[C@@...\n",
      "21'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "22\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "22' for input: 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@H](Cc1ccccc1Br)N...\n",
      "22'\n",
      "[21:21:41] SMILES Parse Error: syntax error while parsing: CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](Cc1ccccc1Br)...\n",
      "5\n",
      "[21:21:41] SMILES Parse Error: Failed parsing SMILES 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](Cc1ccccc1Br)...\n",
      "5' for input: 'CC(C)CN([C@H](CO)CCCCNC(=O)[C@@H](Cc1ccccc1Br)...\n",
      "5'\n",
      "c:\\Users\\Rebe\\Documents\\Python programms\\Capstone\\Draft_1 9-27-2023\\.venv\\Lib\\site-packages\\rdkit\\Chem\\Draw\\IPythonConsole.py:261: UserWarning: Truncating the list of molecules to be displayed to 50. Change the maxMols value to display more.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "mols = [Chem.MolFromSmiles(smi) for smi in val.split(' ') if Chem.MolFromSmiles(smi) is not None]\n",
    "Draw.MolsToGridImage(mols, molsPerRow=5, subImgSize=(200, 200), legends=[str(i) for i in range(len(mols))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.758938 M parameters\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "block_size = 256 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "# ------------\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "data = pd.read_csv('hiv_protease_inhibitors_data_chemlb_full.csv')\n",
    "\n",
    "smiles = list(data['canonical_smiles'])\n",
    "\n",
    "text = str(smiles)\n",
    "\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class GPTLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "        # better init, not covered in the original GPT video, but important, will cover in followup video\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = GPTLanguageModel()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))\n",
    "#open('more.txt', 'w').write(decode(m.generate(context, max_new_tokens=10000)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
